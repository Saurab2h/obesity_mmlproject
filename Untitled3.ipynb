{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saurab2h/obesity_mmlproject/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuatSbZbp1K1",
        "outputId": "a27b70d6-7ba3-45db-9e48-aaf3a6379061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjI8-WY1zV6d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM7r9YTb1H8f",
        "outputId": "4b7c2afc-0e12-469f-f4f2-6510a49a8a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id  Gender        Age    Height      Weight family_history_with_overweight  \\\n",
            "0   0    Male  24.443011  1.699998   81.669950                            yes   \n",
            "1   1  Female  18.000000  1.560000   57.000000                            yes   \n",
            "2   2  Female  18.000000  1.711460   50.165754                            yes   \n",
            "3   3  Female  20.952737  1.710730  131.274851                            yes   \n",
            "4   4    Male  31.641081  1.914186   93.798055                            yes   \n",
            "\n",
            "  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
            "0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
            "1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
            "2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
            "3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
            "4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
            "\n",
            "        TUE       CALC                 MTRANS       WeightCategory  \n",
            "0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n",
            "1  1.000000         no             Automobile        Normal_Weight  \n",
            "2  1.673584         no  Public_Transportation  Insufficient_Weight  \n",
            "3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n",
            "4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15533 entries, 0 to 15532\n",
            "Data columns (total 18 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   id                              15533 non-null  int64  \n",
            " 1   Gender                          15533 non-null  object \n",
            " 2   Age                             15533 non-null  float64\n",
            " 3   Height                          15533 non-null  float64\n",
            " 4   Weight                          15533 non-null  float64\n",
            " 5   family_history_with_overweight  15533 non-null  object \n",
            " 6   FAVC                            15533 non-null  object \n",
            " 7   FCVC                            15533 non-null  float64\n",
            " 8   NCP                             15533 non-null  float64\n",
            " 9   CAEC                            15533 non-null  object \n",
            " 10  SMOKE                           15533 non-null  object \n",
            " 11  CH2O                            15533 non-null  float64\n",
            " 12  SCC                             15533 non-null  object \n",
            " 13  FAF                             15533 non-null  float64\n",
            " 14  TUE                             15533 non-null  float64\n",
            " 15  CALC                            15533 non-null  object \n",
            " 16  MTRANS                          15533 non-null  object \n",
            " 17  WeightCategory                  15533 non-null  object \n",
            "dtypes: float64(8), int64(1), object(9)\n",
            "memory usage: 2.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Load the training and test data\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(train.head())\n",
        "print(train.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0KQ_wuW3yeK"
      },
      "outputs": [],
      "source": [
        "# Example: assume 'target' is your label column\n",
        "X = train.drop('WeightCategory', axis=1)\n",
        "y = train['WeightCategory']\n",
        "\n",
        "# Encode categorical variables (if any) BEFORE splitting\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1XW4Hwe4AGe",
        "outputId": "1ac05bb2-9884-4a8e-e797-54b754f2e13f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.8863855809462504\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--qk0JzX4Eg7",
        "outputId": "fa994560-010b-46ca-ce07-b1dc213ac669"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:10:21] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Predictions saved to submission.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the training and test data\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# =============================================\n",
        "# Separate features and target\n",
        "# =============================================\n",
        "X_train = train.drop(['id', 'WeightCategory'], axis=1)\n",
        "y_train = train['WeightCategory']\n",
        "\n",
        "X_test = test.drop(['id'], axis=1)  # Only features, no target\n",
        "\n",
        "# One-hot encode categorical features\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "\n",
        "# Align columns\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "\n",
        "# Optimized XGBoost\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=23,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.38,\n",
        "    min_child_weight=21,\n",
        "    gamma=0.535,\n",
        "    reg_alpha=5.67e-08,\n",
        "    reg_lambda=9.15,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train_enc)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Map back to original labels\n",
        "y_pred_labels = le.inverse_transform(y_pred)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'id': test['id'], 'WeightCategory': y_pred_labels})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ Predictions saved to submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA_YivNSoIUC",
        "outputId": "4667aa0b-7bf2-4d0c-8823-137f063cf2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:35:44] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Best parameters: {'subsample': 0.8, 'reg_lambda': 2.5, 'reg_alpha': 0.8, 'n_estimators': np.int64(400), 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': np.float64(0.1366666666666667), 'gamma': np.float64(0.4), 'colsample_bytree': 0.6}\n",
            "✅ CV Accuracy: 90.7423363855913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:35:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ submission_randomsearch.csv created\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load the training and test data\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# =============================================\n",
        "# Separate features and target\n",
        "# =============================================\n",
        "X_train = train.drop(['id', 'WeightCategory'], axis=1)\n",
        "y_train = train['WeightCategory']\n",
        "\n",
        "X_test = test.drop(['id'], axis=1)  # Only features, no target\n",
        "\n",
        "# One-hot encode categorical features\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "\n",
        "# Align columns\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "\n",
        "\n",
        "# Base model\n",
        "xgb = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "# Search space\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(300, 600, 50),           # 300–600\n",
        "    'learning_rate': np.linspace(0.01, 0.2, 10),      # small–moderate\n",
        "    'max_depth': [3,5, 7, 9],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': np.linspace(0, 0.4, 5),\n",
        "    'reg_alpha': [0, 0.1,0.4, 0.5, 0.6, 0.8],\n",
        "    'reg_lambda': [1, 1.5, 2, 2.5],\n",
        "\n",
        "}\n",
        "\n",
        "# Randomized search (change n_iter for more/less exploration)\n",
        "rand_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=60,              # 60 random combinations\n",
        "    scoring='accuracy',\n",
        "    cv=5,                   # 5-fold CV on your training data\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rand_search.fit(X_train, y_train_enc)\n",
        "print(\"✅ Best parameters:\", rand_search.best_params_)\n",
        "print(\"✅ CV Accuracy:\", rand_search.best_score_ * 100)\n",
        "\n",
        "# Retrain on full training data\n",
        "best_xgb = rand_search.best_estimator_\n",
        "best_xgb.fit(X_train, y_train_enc)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "y_pred_labels = le.inverse_transform(y_pred)\n",
        "\n",
        "submission = pd.DataFrame({'id': test['id'], 'WeightCategory': y_pred_labels})\n",
        "submission.to_csv(\"submission_randomsearch.csv\", index=False)\n",
        "print(\"✅ submission_randomsearch.csv created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8f9546ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8fc763-4282-428e-af04-affb4aeb50f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cross-validation Accuracy (mean): 0.9074\n",
            "✅ Cross-validation Accuracy (std): 0.0035\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the number of folds\n",
        "n_folds = 5\n",
        "\n",
        "# Get the best estimator from the previous Randomized Search\n",
        "best_xgb = rand_search.best_estimator_\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(best_xgb, X_train, y_train_enc, cv=n_folds, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Print the mean and standard deviation of the cross-validation scores\n",
        "print(f\"✅ Cross-validation Accuracy (mean): {cv_scores.mean():.4f}\")\n",
        "print(f\"✅ Cross-validation Accuracy (std): {cv_scores.std():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZmXbsByeoI6bDGnKHIPrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}